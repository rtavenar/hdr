# Learning sensible representations for time series

Another track of research I have been following over the past years is the
learning of latent representations for time series.
In [Sec 2.1](02/topic_models.html), latent representations consist in mixture
coefficients, _ie._ time series are represented _via_ the amount of presence of
learned topics they hold.
In [Sec 2.2](02/shapelets_cnn.html), time series are represented through their
filter responses, either in a Convolutional Neural Network (CNN) or a variant
of CNN.
Finally, in [Sec 2.3](02/early.html), I consider the task of early
classification of time series. In this context, a method is introduced that
learns an intermediate representation from which both the decision of
triggering classification and the classification itself can be computed.
