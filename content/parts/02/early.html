<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Machine Learning for Time Series</title>
  <meta name="description" content="# Early Classification of Time SeriesEarly classification of time series is the task of performing a classificationas early as possible for an incoming time ...">

  <link rel="canonical" href="https://rtavenar.github.io/hdr/content/parts/02/early.html">
  <link rel="alternate" type="application/rss+xml" title="Machine Learning for Time Series" href="https://rtavenar.github.io/hdr/feed.xml">

  <meta property="og:url"         content="https://rtavenar.github.io/hdr/content/parts/02/early.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Machine Learning for Time Series" />
<meta property="og:description" content="# Early Classification of Time SeriesEarly classification of time series is the task of performing a classificationas early as possible for an incoming time ..." />
<meta property="og:image"       content="https://rtavenar.github.io/hdr/false" />

<meta name="twitter:card" content="summary">


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": "https://rtavenar.github.io/hdr/content/parts/02/early.html",
  "headline": "Machine Learning for Time Series",
  "datePublished": "2020-12-17T16:45:23+01:00",
  "dateModified": "2020-12-17T16:45:23+01:00",
  "description": "# Early Classification of Time SeriesEarly classification of time series is the task of performing a classificationas early as possible for an incoming time ...",
  "author": {
    "@type": "Person",
    "name": "Romain Tavenard"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "https://rtavenar.github.io/hdr",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://rtavenar.github.io/hdr",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/hdr/assets/css/styles.css">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/hdr/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<!-- (mostly) copied from nbconvert configuration -->
<!-- https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/html/mathjax.tpl -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    // Center justify equations in code and markdown cells. Elsewhere
    // we use CSS to left justify single line equations in code cells.
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        linebreaks: { automatic: true },
    },
    
    // Number LaTeX-style equations
    "TeX": {
        equationNumbers: {
          autoNumber: "all"
        }
    }
    
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML' async></script>


  <!-- DOM updating function -->
  <script src="/hdr/assets/js/page/dom-update.js"></script>

  <!-- Selectors for elements on the page -->
  <script src="/hdr/assets/js/page/documentSelectors.js"></script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/hdr';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js" async></script>
  <script src="/hdr/assets/js/page/anchors.js" async></script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->



  <!-- Load the auto-generating TOC (non-async otherwise the TOC won't load w/ turbolinks) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.8.1/tocbot.min.js" async></script>
  <script src="/hdr/assets/js/page/tocbot.js"></script>

  <!-- Google analytics -->
  


  <!-- Clipboard copy button -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script>

  <!-- Load custom website scripts -->
  <script src="/hdr/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/hdr/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/hdr/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  

  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js" async></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>

  <!-- Load JS that depends on site variables -->
  <script src="/hdr/assets/js/page/copy-button.js" async></script>

  <!-- Hide cell code -->
  <script src="/hdr/assets/js/page/hide-cell.js" async></script>

  <!-- Printing the screen -->
  <!-- Include nbinteract for interactive widgets -->
<script src="https://printjs-4de6.kxcdn.com/print.min.js" async></script>
<script>
printContent = () => {
    // MathJax displays a second version of any math for assistive devices etc.
    // This prevents double-rendering in the PDF output.
    var ignoreAssistList = [];
    assistives = document.querySelectorAll('.MathJax_Display span.MJX_Assistive_MathML').forEach((element, index) => {
        var thisId = 'MathJax-assistive-' + index.toString();
        element.setAttribute('id', thisId);
        ignoreAssistList.push(thisId)
    });

    // Print the actual content object
    printJS({
        printable: 'textbook_content',
        type: 'html',
        css: "/hdr/assets/css/styles.css",
        style: "#textbook_content {padding-top: 40px};",
        scanStyles: false,
        targetStyles: ["*"],
        ignoreElements: ignoreAssistList,
        documentTitle: "Made with Jupyter Book"
    })
};

initPrint = () => {
    document.querySelector('#interact-button-print').addEventListener('click', printContent)
}

initFunction(initPrint)
</script>

</head>

  <body>
    <!-- Include the ThebeLab config so it gets reloaded on each page -->
    <script type="text/x-thebe-config">{
    requestKernel: true,
    binderOptions: {
    repo: "rtavenar/hdr",
    ref: "gh-pages",
    },
    codeMirrorConfig: {
    theme: "abcdef",
    mode: "python"
    },
    kernelOptions: {
    kernelName: "python3",
    path: ""
    }
}
</script>

    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  
  <h2 class="c-sidebar__title">Machine Learning for Time Series</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/parts/about">
        <a class="c-sidebar__entry"
          href="/hdr/parts/about.html"
        >
          
          Preamble
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/parts/intro">
        <a class="c-sidebar__entry"
          href="/hdr/parts/intro.html"
        >
          
          Introduction
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/parts/01_metrics">
        <a class="c-sidebar__entry"
          href="/hdr/parts/01_metrics.html"
        >
          
            1.
          
          Defining Adequate Metrics for Structured Data
        </a>
      </li>

      
      

      

      
      

      
        

        

        <ul class="c-sidebar__sections">
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/parts/01/temporal_kernel">
              <a class="c-sidebar__entry"
                href="/hdr/parts/01/temporal_kernel.html"
              >
                
                  1.1
                
                A Temporal Kernel for Time Series
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/parts/01/dtw">
              <a class="c-sidebar__entry"
                href="/hdr/parts/01/dtw.html"
              >
                
                  1.2
                
                Dynamic Time Warping
              </a>
            </li>
            
              
              <ul class='c-sidebar__subsections'>
              
                
                
                
                
                <li class="c-sidebar__subsection" data-url="/parts/01/dtw/dtw_warping_length">
                  <a class="c-sidebar__entry"
                    href="/hdr/parts/01/dtw/dtw_warping_length.html"
                  >
                    
                      1.2.1
                      
                    
                    Constrained Dynamic Time Warping
                  </a>
                </li>
              
                
                
                
                
                <li class="c-sidebar__subsection" data-url="/parts/01/dtw/dtw_da">
                  <a class="c-sidebar__entry"
                    href="/hdr/parts/01/dtw/dtw_da.html"
                  >
                    
                      1.2.2
                      
                    
                    DTW Alignment as an Adaptive Resampling Strategy
                  </a>
                </li>
              
                
                
                
                
                <li class="c-sidebar__subsection" data-url="/parts/01/dtw/dtw_gi">
                  <a class="c-sidebar__entry"
                    href="/hdr/parts/01/dtw/dtw_gi.html"
                  >
                    
                      1.2.3
                      
                    
                    DTW with Global Invariances
                  </a>
                </li>
              
              </ul>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/parts/01/ot">
              <a class="c-sidebar__entry"
                href="/hdr/parts/01/ot.html"
              >
                
                  1.3
                
                Optimal Transport for Structured Data
              </a>
            </li>
            
            
          
        </ul>
      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/parts/02_representations">
        <a class="c-sidebar__entry"
          href="/hdr/parts/02_representations.html"
        >
          
            2.
          
          Learning Sensible Representations for Time Series
        </a>
      </li>

      
      

      

      
      

      
        

        

        <ul class="c-sidebar__sections">
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/parts/02/topic_models">
              <a class="c-sidebar__entry"
                href="/hdr/parts/02/topic_models.html"
              >
                
                  2.1
                
                Temporal Topic Models
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/parts/02/shapelets_cnn">
              <a class="c-sidebar__entry"
                href="/hdr/parts/02/shapelets_cnn.html"
              >
                
                  2.2
                
                Shapelet-based Representations and Convolutional Models
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/parts/02/early">
              <a class="c-sidebar__entry"
                href="/hdr/parts/02/early.html"
              >
                
                  2.3
                
                Early Classification of Time Series
              </a>
            </li>
            
            
          
        </ul>
      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/parts/conclu">
        <a class="c-sidebar__entry"
          href="/hdr/parts/conclu.html"
        >
          
          Perspectives
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li class="c-sidebar__divider"></li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/contributing">
        <a class="c-sidebar__entry"
          href="/hdr/contributing.html"
        >
          
          Feedback welcome
        </a>
      </li>

      
      

      

      
      

      

      
    
  </ul>
  <p class="sidebar_footer">Romain Tavenard's HDR thesis.<br />Powered by <a href='https://jupyterbook.org'>Jupyter Book</a>.</p>
</nav>

      
      <div class="c-topbar" id="top-navbar">
  <!-- We show the sidebar by default so we use .is-active -->
  <div class="c-topbar__buttons">
    <button
      id="js-sidebar-toggle"
      class="hamburger hamburger--arrowalt is-active"
    >
      <span class="hamburger-box">
        <span class="hamburger-inner"></span>
      </span>
    </button>
    <div class="buttons">
<div class="download-buttons-dropdown">
    <button id="dropdown-button-trigger" class="interact-button"><img src="/hdr/assets/images/download-solid.svg" alt="Download" /></button>
    <div class="download-buttons">
        
        <a id="interact-button-print"><button id="interact-button-download" class="interact-button">.pdf</button></a>
    </div>
</div>


</div>

  </div>
  <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
  <aside class="sidebar__right">
    <header><h4 class="nav__title"><img src="/hdr/assets/images/list-solid.svg" alt="Search" />   On this page</h4></header>
    <nav class="onthispage">
    </nav>
  </aside>
  <a href="/hdr/search.html" class="topbar-right-button" id="search-button">
    <img src="/hdr/assets/images/search-solid.svg" alt="Search" />
  </a>
</div>

      <main class="c-textbook__page" tabindex="-1">
            <div class="c-textbook__content" id="textbook_content">
              <h1 id="early-classification-of-time-series">Early Classification of Time Series</h1>

<p>Early classification of time series is the task of performing a classification
as early as possible for an incoming time series.</p>

<p>I have worked on two methods for this task.
The first one is a slight improvement over
<a class="citation" href="#dachraoui2015early">(Dachraoui, Bondu, &amp; Cornuéjols, 2015)</a> and the second one relies on a
representation-learning strategy.</p>

<h2 id="optimizing-a-composite-loss-for-early-classification">Optimizing a Composite Loss for Early Classification</h2>

<p><a class="citation" href="#dachraoui2015early">(Dachraoui, Bondu, &amp; Cornuéjols, 2015)</a> introduces a composite loss function for early
classification of time series that balances earliness and accuracy.</p>

<p>The cost function is of the following form:</p>

<p>\begin{equation}
\mathcal{L}(\mathbf{x}<em>{\rightarrow t}, y, t, \boldsymbol{\theta}) =
    \mathcal{L}_c(\mathbf{x}</em>{\rightarrow t}, y, \boldsymbol{\theta}) + \alpha t
\label{eq:loss_early}
\end{equation}</p>

<p>where $\mathcal{L}_c(\cdot,\cdot,\cdot)$ is a
classification loss and $t$ is the time at which a
decision is triggered by the system.
In this setting, $\alpha$ drives the tradeoff between accuracy and earliness
and is supposed to be a hyper-parameter of the method.</p>

<p>The authors rely on (i) a clustering of the
training
time series and (ii) individual classifiers $m_t(\cdot)$ trained at all possible
timestamps, so as to be able to predict, at time $t$, an expected cost for all
times $t + \tau$ with $\tau \geq 0$:</p>

<p>\begin{equation}
    f_\tau(\mathbf{x}<em>{\rightarrow t}, y) =
    \sum_k \left[ P(C_k | \mathbf{x}</em>{\rightarrow t})
     \sum_i \left( P(y=i | C_k)
     \left( \sum_{j \neq i} P_{t+\tau}(\hat{y} = j | y=i, C_k)
     \right) \right)
     \right]
        + \alpha t
        \label{eq:dachraoui}
\end{equation}</p>

<p>where:</p>

<ul>
  <li>$P(C_k | \mathbf{x}<em>{\rightarrow t})$ is a soft-assignment weight of
$\mathbf{x}</em>{\rightarrow t}$ to cluster $C_k$;</li>
  <li>$P(y=i | C_k)$ is obtained from a contingency table that stores the number of
training time series of each class in each cluster;</li>
  <li>$P_{t+\tau}(\hat{y} = j | y=i, C_k)$ is obtained through training time
confusion matrices built on time series from cluster $C_k$ using classifier
$m_{t+\tau}(\cdot)$.</li>
</ul>

<p>At test time, if a series is observed up to time $t$ and if, for all positive
$\tau$ we have
$f_\tau(\mathbf{x}<em>{\rightarrow t}, y) \geq f_0(\mathbf{x}</em>{\rightarrow t}, y)$,
then a decision is made using classifier $m_t(\cdot)$.</p>

<h3 id="limitations-of-the-clustering">Limitations of the clustering</h3>

<!-- #region {"tags": ["popout"]} -->
<p><strong>Note.</strong> This unpublished note is part of François Painblanc’s PhD work.
We are co-supervising François together with Laetitia Chapel and Chloé Friguet.
<!-- #endregion --></p>

<p>Relying on Equation \eqref{eq:dachraoui} to decide prediction time can be
tricky. We show in the following that in some cases (related to specific
configurations of the training time confusion matrices), such an approach will
lead to undesirable behaviors.</p>

<p>Using Bayes’ rule, Equation \eqref{eq:dachraoui} can be re-written</p>

<p>\begin{eqnarray}
    f_\tau(\mathbf{x}<em>{\rightarrow t}, y) &amp;=&amp;
        \sum_k P(C_k | \mathbf{x}</em>{\rightarrow t})
        \sum_i
        \sum_{j \neq i} P_{t+\tau}(\hat{y} = j, y=i | C_k)
        + \alpha t <br />
    &amp;=&amp;
        \sum_k P(C_k | \mathbf{x}<em>{\rightarrow t})
        \underbrace{\sum_i 1 - P</em>{t+\tau}(\hat{y} = i, y=i | C_k)}<em>{A</em>{t+\tau}(C_k)}
        + \alpha t <br />
\end{eqnarray}</p>

<p>where $A_{t+\tau}(C_k)$ is the sum of off-diagonal elements in the (normalized)
training time confusion matrix built from time series in cluster $k$ using
classifier $m_{t+\tau}(\cdot)$.</p>

<p>In practice, this means that if the sum of off-diagonal elements of confusion
matrices is equal to the same $A_{t+\tau}$ for all clusters, then this method
will make a decision on the most adequate prediction time without taking the
data $\mathbf{x}_{\rightarrow t}$ into account:</p>

<p>\begin{eqnarray}
    f_\tau(\mathbf{x}<em>{\rightarrow t}, y) &amp;=&amp;
        \sum_k P(C_k | \mathbf{x}</em>{\rightarrow t})
        A_{t+\tau}
        + \alpha t <br />
     &amp;=&amp;
        A_{t+\tau} + \alpha t <br />
\end{eqnarray}</p>

<p>In other words, for this method to adapt the decision time $t$ in a
data-dependent fashion, it is important that accuracy differs
significantly between clusters, which is a condition that is difficult to ensure
<em>a priori</em>.</p>

<h3 id="pushing-the-method-to-the-limit-case">Pushing the Method to the Limit Case</h3>

<p>In <a class="citation" href="#tavenard:halshs-01339007">(Tavenard &amp; Malinowski, 2016)</a>, we pushed this method to its limit case
where the number of clusters is equal to the number of training time series.
In this case, the limitation exposed above does not hold anymore.</p>

<p>We showed superior loss optimization capabilities with this approach, at the
cost of a larger computational complexity.</p>

<p>We also showed that in order to limit inference time complexity, one could
learn a <em>decision triggering classifier</em> that, based on the time series
$\mathbf{x}<em>{\rightarrow t}$, predicts whether a decision should be triggered
or not.
In this setting, the target values $\gamma_t$ used to train this
_decision triggering classifier</em>
were computed from expected costs $f_\tau$ presented above:</p>

<p>\begin{equation}
    \gamma_t(\mathbf{x}<em>{\rightarrow t}, y) = \left{
        \begin{array}{l}
            1 \text{ if } f</em>{0}(\mathbf{x}<em>{\rightarrow t}, y) =
                \min</em>{\tau \geq 0} f_{\tau}(\mathbf{x}_{\rightarrow t}, y) <br />
            0 \text{ otherwise. }
        \end{array} \right.
\end{equation}</p>

<p>In other words, decision making is here seen as a two-step process where a
first classifier (<em>decision triggering classifier</em>) decides whether a decision
should be made, in which case a
second classifier is used to determine the class to be predicted (the latter
classifier is $m_t(\cdot)$, the same as for other methods).</p>

<h2 id="representation-learning-for-early-classification">Representation Learning for Early Classification</h2>

<!-- #region {"tags": ["popout"]} -->
<p><strong>Note.</strong> This work is part of Marc Rußwurm’s PhD work.
Marc is a PhD student from TU Munich who came to France for a
4-month period in 2018-2019. I was co-supervising Marc with Nicolas Courty
and Sébastien Lefèvre during his stay.
<!-- #endregion --></p>

<p>The previous approach has several shortcomings.
First, it requires to learn a classifier $m_t(\cdot)$ for each possible time
series length $t$, which is very costly.
Second, both classifiers (the one that decides whether a decision should be
made, and the one that actually makes the decision) are seen as independent
models, while they are, in practice, closely related.
Finally, the loss function presented in Equation \eqref{eq:loss_early} requires
a careful choice of hyper-parameter $\alpha$ that might not be easy to
determine in
practice.</p>

<p>We have hence proposed a representation learning framework that
addresses these three limitations <a class="citation" href="#ruwurm:hal-02174314">(Rußwurm et al., 2019)</a>.</p>

<p>In more detail, we rely on a feature extraction module (that can either be
made of causal convolutions or recurrent submodules) to extract a fixed-sized
representation $h_t$ from an incoming time series $\mathbf{x}_{\rightarrow t}$.
An important point here is that this feature extractor should operate on time
series whatever their length (and hence a different feature extractor need not
to be learned for each time series length).
Then, this feature is provided as input to two different heads, as shown in the
following Figure (in which grey cells correspond to quantities that are
computed from the model outputs):</p>

<p><img src="../../images/tex/early_module_cropped.svg" alt="half-width" /></p>

<ul>
  <li>The first head (left) outputs a probability $p_\text{dec}$ of making a
decision at
time $t$ <strong>given that no decision has been made before</strong>: it plays the same role
as the <em>decision triggering classifier</em> presented above and from the series of
$p_\text{dec}$ values, one can compute the probability $P_t$ of making a
decision at time $t$;</li>
  <li>The second head is the standard classification head that effectively produces
a classification if the first head triggered it.</li>
</ul>

<p>Hence, provided that we have a differentiable early classification loss
function, we are able to learn all parameters of this model end-to-end.
Our last contribution in this context is the design of a loss function that
does not lead to dumb optimal solutions (<em>e.g.</em> trigger all classifications at
the first time stamp, whatever the data).
We introduced the following loss function:</p>

<p>\begin{equation}
    \mathcal{L}(\mathbf{x}<em>{\rightarrow t}, y, t, \boldsymbol{\theta}) =
        \alpha \mathcal{L}_c(\mathbf{x}</em>{\rightarrow t}, y, \boldsymbol{\theta})
            - (1-\alpha) P_\boldsymbol{\theta}(m_t(\mathbf{x}_{\rightarrow t})=y)
            \left( \frac{T-t}{T} \right)
\end{equation}</p>

<p>where $P_{\boldsymbol{\theta}}(m_t(\mathbf{x}<em>{\rightarrow t})=y)$ is the
probability (as
assigned by the classification model) to generate $y$ as an output and $T$ is
the total length of the time series (_i.e.</em> the maximum timestamp at which
a decision can be made).
The second part in this loss function is an earliness reward, which is taken
into account iff the provided decision is sound (<em>i.e.</em> the correct class is
predicted with non-zero probability).
When the decision time is drawn from the
multinomial distribution of parameters ${P_t}<em>{t \in [0, T-1]}$, the overall
loss is now:
\begin{equation}
    \mathbb{E}</em>{t \sim \mathcal{M}(P_0, \dots , P_{T-1})}
        \mathcal{L}(\mathbf{x}_{\rightarrow t}, y, t, \boldsymbol{\theta})
\end{equation}
and gradients can be back-propagated through both heads of the model, hence
allowing to jointly learn the early decision mechanism and the predictor.</p>

<p>We have shown that this model outperforms all known baselines in terms of both
time complexity and earliness/accuracy tradeoff, especially for large scale
datasets.
Moreover, we have presented an application of this model to the monitoring of
agriculture, and demonstrated its ability to trigger class-specific early decisions
in this context in <a class="citation" href="#ruwurm:hal-02343851">(Rußwurm, Tavenard, Lefèvre, &amp; Körner, 2019)</a>.</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="dachraoui2015early">Dachraoui, A., Bondu, A., &amp; Cornuéjols, A. (2015). Early classification of time series as a non myopic sequential decision making problem. In <i>Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery</i> (pp. 433–447). Springer.</span></li>
<li><span id="tavenard:halshs-01339007">Tavenard, R., &amp; Malinowski, S. (2016). Cost-Aware Early Classification of Time Series. In <i>Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery</i> (pp. 632–647). Riva del Garda, Italy.</span></li>
<li><span id="ruwurm:hal-02174314">Rußwurm, M., Lefevre, S., Courty, N., Emonet, R., Körner, M., &amp; Tavenard, R. (2019). <i>End-to-end Learning for Early Classification of Time Series</i>.</span></li>
<li><span id="ruwurm:hal-02343851">Rußwurm, M., Tavenard, R., Lefèvre, S., &amp; Körner, M. (2019). Early Classification for Agricultural Monitoring from Satellite Time Series. In <i>AI for Social Good Workshop at International Conference on Machine Learning (ICML)</i>. Long Beach, United States.</span></li></ol>

            </div>
            <div class="c-textbook__footer" id="textbook_footer">
              
<nav class="c-page__nav">
  

  
</nav>

              <footer>
  <p class="footer"></p>
</footer>

            </div>

        </div>
      </main>
    </div>
  </body>
</html>
